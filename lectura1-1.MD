
In this paper, collaborative filtering technique has been introduced to sift the most valuable data but this technique has two challenges: the first is to improve the scalability and the second is improve the quality of the recommendations for the users. Then, they discussed two variants memory-based and model-based approaches. Therefore, they addressed these issues of recommender systems by applying a different approach item-based algorithm. After that, to compute the similarity between items and then to select the most similar items, there are various methods such as cosine-based similarity, correlation-based similarity and adjusted-cosine similarity. Also some techniques have been explained to compute the prediction like Weighted Sum and Regression. Furthermore, they employed data from our MovieLens recommender system.  They used 80% of data as training set, 20% as a test set and also sparsity level of data sets. They utilized MAE as an evaluation metric to report prediction experiments. To Experimental Procedure they determined the sensitivity of different parameters to different algorithms. Then Pearson nearest neighbor algorithm has been used to Benchmark user-based system. In order to obtain recommendations, they used weighted sum vs. regression model. Finally, they suggested that item-based algorithms provide dramatically better performance than user-based algorithms, while at the same time providing better quality than the best available user-based algorithms.
On the one hand, these are positive points: that they used the best algorithm such as Pearson nearest neighbor algorithm and regression-based algorithm then compared the results accurately. For example, by employing Pearson nearest neighbor algorithm they find every possible neighbor to form optimal neighborhoods.
Moreover, in this paper Item Similarity Computation, Prediction Computation, Performance Implications have been explained clearly. I can understand the concept of these technique well. They used some figures to clear concepts of similarity computing such as figure 2 could show concept of co-rated items and similarity computation.
Furthermore, they used a data set with enough data. So, they could study them and obtained suitable results that  
On the other hand, in my opinion, these are negative points for this paper: they divided the database into a training set and a test set. In fact, the percentage of training set and test set are 80% and 20%, respectively. However, in my opinion, the percentage of training set are very big and the percentage of test set is very small. It would be desirable a stability analysis testing with different percentage of splitting because it could have an impact on the quality results and performance results. So, they should have used 60% and 40% for training set and data test, respectively.
Furthermore, in the part of Experimental Results, they used Cosine-based Similarity, adjusted cosine similarity and etc. First, in this paper computing similarity for the specific data set has not been shown. They should have been shown their similarity computations for the data set to convince readers. Secondly, in my opinion, in view of the fact that the similarity is measured by computing the cosine of the angle between two vectors, it cannot be very accurate. Hence, they should have concentrated on split cosine similarity into several key components and update the components instead of recomputing similarity with adjusted cosine and correlation and extend technique of basic cosine.
In addition, in part of result they focused a lot on MAE. In fact, there could be more dimensions to evaluate several techniques and performances. I think that they concentrated on only one criterion. Therefore, they also could use MSE and RMSE techniques so as to have various result and comparisons.
