In this paper, they have presented a generic optimization for personalized ranking. They analyzed the problem settings and presented a different approach for that. Then they have optimized criterion BPR-Opt is the maximum posterior estimator that is derived from a Bayesian analysis of the problem. In view of the fact that standard gradient descent is not the right choice for their problem, they propose Learn BPR, a stochastic gradient-descent algorithm based on bootstrap sampling of training triples to solve the problem. Then they explained models of matrix factorization and adaptive kNN to use their proposed model. Finally, they have shown that their optimized method has had better performances compare to other same models and BPR optimization method is the right choice for the important task of personalized ranking.

On the one hand, the authors used a different approach by using item pairs as training data and optimize for ranking item pairs instead of scoring single items as this better represents the problem than just replacing missing values with negative ones. In my opinion, it is positive points for their approach because their training data consists of both positive and negative pairs and missing values. In addition, this optimization decreases the number of missing values. So, they have predictions with more accurate with actual objective of ranking. 

Moreover, it is kind of merit that figures 1 and 2 could have a suitable visualization for readers, they could explain how to calculated the userâ€™s preferences for items or how to skipped some of preferences that they could not infer anything from those well. So, I could understand it well.

One of the other positive points of this paper is that the authors used BPR and optimized, one of the powerful method to solve personalized ranking task. In my opinion, they explained the steps of their optimization of BPR and posterior estimator for optimal personalized ranking well. In addition, in general they used various methods to obtain results. It is one of the another merit in this paper. Because they have tested their model with several conditions.

It is interesting for me, although most of these kinds of articles just have been studied either on implicit or explicit feed the authors used two kinds of datasets for example one dataset with an explicit feedback for Netflix dataset and another is an implicit feedback for purchases records. They could compare the results and reached interested results. 

On the other hand, they used some of algorithms to explain and study their models. But there is no discussion of SVD with the model. In my opinion, they should have studied the model with SVD too as an another popular method, although they spoke several times about that. So, I think that if they would use that, they could improve the result with comparison of some known methods.

Furthermore, the authors wrote that if a user has viewed an item i1 and not item i2, they assumed that the user has preferred i2. In my opinion, this is not an appropriate and correct assumption. Because maybe the user is not aware of presence of item i2. It does not mean the user does not like the item.  
