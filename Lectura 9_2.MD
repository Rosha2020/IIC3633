
In this paper, they modeled carousel personalization as a contextual multi-armed bandit problem with multiple plays, stochastic arm displays and delayed batch feedback. To create the model, they introduced their framework. First of all, they explained the Multi-Armed Bandits with Multiple Plays for Carousel Personalization. Then they studied Leveraging Contextual Information on User Preferences that they explained and compared Semi-Personalization via User Clustering and Contextual Multi-Armed Bandits. In their framework, they used Stochastic Card Display, Delayed Feedback to Capture Characteristics of Real-World Carousels. Then they studied a large-scale carousel-based playlist recommendation task on the global mobile app Deezer. To evaluate of Carousel-Based Recommendation, they designed a simulated environment in Python for offline experiments. Finally, after explaining their algorithm, they compared their online and offline experiments results.

One of the positive point for this paper is their algorithm. Because they combined some methods such as the Upper Confidence Bound which try to establish an upper bound on the expected reward (such bound gets closer to the observed mean as more observations are accumulated, thereby balancing exploration and exploitation, Thompson Sampling strategy which takes a Bayesian perspective aiming to choose an arm according to its probability of being the best arm and another method. But I think that they could add another method which is called LinUCB. Consequently, they could have more interesting results. Because as its name suggests uses a linear function estimator with an upper bound on the expected rewards (one estimator per arm, all independent of each other), has proved to be a popular approach and many works build upon it in variations of its proposed scenario, such as when adding similarity information. 

Moreover, it is very important that identify sequence of using those methods or algorithms that they did not point out about it. I think that they should have designated order of using the methods and then explained that why did use for example the UCB strategy as the second or third algorithm for their contextual multi-armed bandit.

Furthermore, it is kind of the demerit because they used the contextual bandits scenario to model their method but they did not point out to some challenges of employing contextual bandits. For example, when there is just one value or one label. One issue that makes the contextual bandits scenario harder is that most supervised learning algorithms used as oracles cannot be fit to data that has only one value or only one label. For example, only observations which had no reward. Therefore, the algorithm is faced cold-start problem. They should have studied some challenges about the contextual bandits like cold-start problem and presented some solution for that.

Also, they stated Semi-Personalization via User Clustering strongly depends on the quality of the underlying user clustering. Also in a Simulation Environment and Dataset for Offline Evaluation of Carousel-Based Recommendation, a k-means clustering was also performed to assign each user to a single cluster. It is a negative point that they expressed twice about user clustering but they did not explain how did they cluster users? Which method is better for their data? So, according to a large-scale carousel-based playlist recommendation task on the global mobile app Deezer with k= 862. They should have clustered their data with the convergent K-means algorithm and its ANN equivalent, the Kohonennet, have been used to cluster large data sets. First of all because its time complexity is O(mkl), where m is the number of instances, k is the number of clusters; and l is the number of iterations taken by the algorithm to converge. Typically, k and l are fixed in advance and so the algorithm has linear time complexity in the size of the data set. Secondly, its space complexity is O(k+m). It requires additional space to store the data matrix. It is possible to store the data matrix in a secondary memory and access each pattern based on need. However, this scheme requires a huge access time because of the iterative nature of the algorithm.  As a consequence, processing time increases enormously. Finally, it is order-independent.  For a given initial seed set of cluster centers, it generates the same partition of the data irrespective of the order in which the patterns are presented to the algorithm.

