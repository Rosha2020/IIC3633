
In this paper, they defined a unifying evaluation framework, called ResQue, which wants to measure the qualities of the recommended items, the system’s usability, usefulness, interface and interaction qualities, users’ satisfaction with the systems, and the influence of these qualities on users’ belief of the transparency, ease of use, usefulness, sense of control of the system, and users’ overall satisfaction and trust with the systems, and how these qualities influence and motivate users’ behavioral intentions, including their intention to return to the system and purchase the recommended products. They mixed and validated some available criteria into a well-balanced user-centric evaluation framework for recommender systems. Finally, they created two version types (long and short) of questionnaires which can be implied to evaluate various types of recommenders including rating-based, utility-based, and knowledge-based systems regardless of the backend engines used.

In my opinion, it is positive point that they pointed that their future work will include further analysis and collection of user data to understand cultural influences (European vs. Asian users) as well as the influence of the data domains (entertainment vs. ecommerce) on users’ attitudes and behaviors. But I think that they should study and analyze seasons influences on users’ attitudes and behaviors. For example, there are some commercial websites to sell clothes. The web site has some recommenders to sell some warm clothes in winter for users that live in north hemisphere that these recommenders are not suitable for users who live in south hemisphere in summer. So, I believe that seasons have crucial effect on users’ attitudes and behaviors that they usually have not paid attention to that. If it is paid attention to it, commercial website could have more appropriate recommenders for users in the world and consequently they can significantly enhance users’ likelihood to buy the items recommended to them and their overall satisfaction and loyalty, increasing users’ likelihood to return to the site.

They studied and explained fifteen constructs such as perceived accuracy, perceived usefulness of a recommender and etc. I think that it is positive point for this research. Because this paper is a useful resource to learn definitions of wide range of criteria and to understand concepts of success factors of recommender systems regardless of accuracy measures. 

In part of structural model, they found causal relationships among their evaluation constructs and created structural model fit with path significance. It is interesting for me because they could show the relations with a figure that makes me understandable. Consequently, they could understand which constructs have more effect on User Beliefs, User Attitudes and Behavioral Intentions. But first of all, they did not explain who they calculated values of β and p. Secondly, in my opinion this kind of evaluate is not appropriate or fair, maybe it has created some biases. If all of constructs would have equal (same) role in evaluation their evaluation can be fair. In fact, each of the constructs has specific and equal proportion in evaluation, they can evaluate which one of the construct has the most effect on for example User Beliefs. But I think that for example if a web site to sell somethings would have strong interface Adequacy and weak Novelty, all of these computation is influenced and these evaluations cannot be correct. In fact, I do not think that there is a recommender system which uses all of those constructs with equal portion. So, it is negative point for the paper. In addition, at least they could express a default that they assumed that all of their constructs have a same portion in the evaluation. 

Although they put link of their survey, I think that they needed to show at least on type of questionnaires that they used to survey.  Because readers usually do not pay attention to footnotes and refers to the link. It also could make the paper more tangible to see some visual example in terms of making a suitable interface between readers and papers.
